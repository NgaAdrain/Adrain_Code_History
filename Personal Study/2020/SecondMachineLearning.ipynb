{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondMachineLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9CiVqLD2zKO",
        "colab_type": "text"
      },
      "source": [
        "Quick, Draw! 데이터 집합을 이용한 손그림 인식 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYn0gP4ApX5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ea7fce1-b8d4-433f-8ecb-03846f56d92b"
      },
      "source": [
        "a=500\n",
        "b=500\n",
        "a is b\n",
        "a=400\n",
        "b=400\n",
        "a is b\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XI7bR5R2uEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "c96b64fc-e942-4832-8bd8-a281b47b5966"
      },
      "source": [
        "# Import the TensorFlow\n",
        "\"\"\"\n",
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\"\"\"\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import argparse\n",
        "import ast\n",
        "import functools\n",
        "import sys\n",
        "import numpy\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbPI6NVuGBqO",
        "colab_type": "text"
      },
      "source": [
        "Quick, Draw 데이터 셋은 기본 tensorflow에 없다!\n",
        "\n",
        "-> 공식 페이지에서 받아와야한다.\n",
        "\n",
        "https://github.com/googlecreativelab/quickdraw-dataset\n",
        "\n",
        "이번에 TFRecord형식으로 처리가 되어있는 데이터들을 불러서 처리해보도록 하자.\n",
        "\n",
        "현재 데이터들은 드라이브에 올려져 있으므로 드라이브에 \n",
        "\n",
        "먼저 colab python notebook을 mount한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ynNtq7SuZkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2rr25CRKEKn",
        "colab_type": "text"
      },
      "source": [
        "위의 과정에서 colab notebook과 google drive를 mount하여 gdrive폴더에 연결하였다.\n",
        "\n",
        "본인의 드라이브에는 dataset이 gdrive/My\\ Drive/quickdraw_tutorial_dataset_v1에 위치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSYHTzt9OXh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0c1b8db7-4cc4-4fdd-84c3-59bbafc78cc7"
      },
      "source": [
        "!pip install absl-py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZOyoyy92vf1",
        "colab_type": "text"
      },
      "source": [
        "아래의 코드는 정상적으로 작동한다.\n",
        "\n",
        "파이썬을 실행한다. 현재폴더/drive/My\\ Drive의 train_model.py를 실행하는데\n",
        "\n",
        "--training_data argument로 training.tfrecord-?????-of-????? 형식의 파일을\n",
        "\n",
        "--eval_data argument로 eval.tfrecord-?????-of-????? 형식의 파일을\n",
        "\n",
        "--classes_file argument로 training.tfrecord.classes 파일을 인자로 넘겨줌\n",
        "\n",
        "★중요! --model_dir argument로 model이 정의되어있는 train_model.py 파일을 인자로 넘겨줘야 한다!!!\n",
        "\n",
        "=> 이걸 안해서 오류가 났었다.\n",
        "\n",
        "현재 설정 : training step => 100000번\n",
        "\n",
        "=> 100번 씩 training & 300번째 step마다 checkpoint저장.\n",
        "\n",
        "100 step 당 빠르면 60sec ~ 느리면 110sec 소요\n",
        "\n",
        "=> 100000번 step의 training ==> 85000000sec = 141666.7min = 2361.1 hour = 98일 소요(?????????????)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJBOe_9eIub1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d62c853-6eb1-45d8-c882-a7b71fbdbe28"
      },
      "source": [
        "#'eval.tfrecord-0000' + 1~9 + '-of-00010'\n",
        "#'eval.tfrecord.classes'\n",
        "#'training.tfrecord-0000' + 1~9 + '-of-00010'\n",
        "#'training,tfrecord.classes\n",
        "!python ./drive/My\\ Drive/train_model.py \\\n",
        "    --training_data=drive/My\\ Drive/quickdraw_tutorial_dataset_v1/training.tfrecord-?????-of-????? \\\n",
        "    --eval_data=drive/My\\ Drive/quickdraw_tutorial_dataset_v1/eval.tfrecord-?????-of-????? \\\n",
        "    --classes_file=drive/My\\ Drive/quickdraw_tutorial_dataset_v1/training.tfrecord.classes \\\n",
        "    --steps=5000 \\\n",
        "    --model_dir=train_model.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0219 11:07:12.366112 139665004287872 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I0219 11:07:12.910996 139665004287872 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:41: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0219 11:07:13.414143 139665004287872 module_wrapper.py:139] From ./drive/My Drive/train_model.py:41: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'train_model.py', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05e7be34a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0219 11:07:13.416967 139665004287872 estimator.py:212] Using config: {'_model_dir': 'train_model.py', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05e7be34a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0219 11:07:13.418116 139665004287872 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0219 11:07:13.418335 139665004287872 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
            "I0219 11:07:13.418603 139665004287872 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0219 11:07:13.428725 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0219 11:07:13.537961 139665004287872 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0219 11:07:13.538442 139665004287872 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0219 11:07:13.539035 139665004287872 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "W0219 11:07:13.539542 139665004287872 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:99: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "W0219 11:07:13.688598 139665004287872 deprecation.py:323] From ./drive/My Drive/train_model.py:99: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:100: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0219 11:07:13.699819 139665004287872 deprecation.py:323] From ./drive/My Drive/train_model.py:100: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0219 11:07:13.734785 139665004287872 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:160: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "W0219 11:07:13.739357 139665004287872 deprecation.py:323] From ./drive/My Drive/train_model.py:160: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0219 11:07:13.740947 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:152: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "W0219 11:07:13.761457 139665004287872 deprecation.py:323] From ./drive/My Drive/train_model.py:152: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:169: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0219 11:07:13.818033 139665004287872 deprecation.py:323] From ./drive/My Drive/train_model.py:169: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "W0219 11:07:13.831422 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0219 11:07:13.831864 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0219 11:07:13.897316 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0219 11:07:13.906645 139665004287872 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0219 11:07:13.926454 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:214: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0219 11:07:14.557570 139665004287872 deprecation.py:323] From ./drive/My Drive/train_model.py:214: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:228: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
            "\n",
            "W0219 11:07:14.577336 139665004287872 module_wrapper.py:139] From ./drive/My Drive/train_model.py:228: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From ./drive/My Drive/train_model.py:241: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0219 11:07:16.183723 139665004287872 module_wrapper.py:139] From ./drive/My Drive/train_model.py:241: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0219 11:07:16.208311 139665004287872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0219 11:07:16.210071 139665004287872 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0219 11:07:16.861322 139665004287872 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-19 11:07:16.871761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-19 11:07:16.872015: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8fc68c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-19 11:07:16.872045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-19 11:07:16.874959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-19 11:07:16.877535: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-19 11:07:16.877590: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (75d104e51fc0): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Restoring parameters from train_model.py/model.ckpt-3662\n",
            "I0219 11:07:16.883082 139665004287872 saver.py:1284] Restoring parameters from train_model.py/model.ckpt-3662\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0219 11:07:17.074754 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0219 11:07:17.178844 139665004287872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0219 11:07:17.232827 139665004287872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 3662 into train_model.py/model.ckpt.\n",
            "I0219 11:07:18.700392 139665004287872 basic_session_run_hooks.py:606] Saving checkpoints for 3662 into train_model.py/model.ckpt.\n",
            "2020-02-19 11:07:30.109838: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 240143 of 1000000\n",
            "2020-02-19 11:07:40.109286: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 483590 of 1000000\n",
            "2020-02-19 11:07:50.109470: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 726258 of 1000000\n",
            "2020-02-19 11:08:00.109368: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 969091 of 1000000\n",
            "2020-02-19 11:08:01.412625: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:195] Shuffle buffer filled.\n",
            "INFO:tensorflow:loss = 5.427088, step = 3663\n",
            "I0219 11:08:02.543706 139665004287872 basic_session_run_hooks.py:262] loss = 5.427088, step = 3663\n",
            "ㅁ\n",
            "ㅁ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "INFO:tensorflow:global_step/sec: 1.564\n",
            "I0219 11:09:06.481559 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.564\n",
            "INFO:tensorflow:loss = 4.753395, step = 3763 (63.940 sec)\n",
            "I0219 11:09:06.483421 139665004287872 basic_session_run_hooks.py:260] loss = 4.753395, step = 3763 (63.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.61408\n",
            "I0219 11:10:08.436470 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.61408\n",
            "INFO:tensorflow:loss = 4.8591814, step = 3863 (61.955 sec)\n",
            "I0219 11:10:08.438357 139665004287872 basic_session_run_hooks.py:260] loss = 4.8591814, step = 3863 (61.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.69294\n",
            "I0219 11:11:07.504951 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.69294\n",
            "INFO:tensorflow:loss = 4.843723, step = 3963 (59.069 sec)\n",
            "I0219 11:11:07.506909 139665004287872 basic_session_run_hooks.py:260] loss = 4.843723, step = 3963 (59.069 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.55071\n",
            "I0219 11:12:11.991527 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.55071\n",
            "INFO:tensorflow:loss = 6.922446, step = 4063 (64.487 sec)\n",
            "I0219 11:12:11.993726 139665004287872 basic_session_run_hooks.py:260] loss = 6.922446, step = 4063 (64.487 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4074 into train_model.py/model.ckpt.\n",
            "I0219 11:12:19.121488 139665004287872 basic_session_run_hooks.py:606] Saving checkpoints for 4074 into train_model.py/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0219 11:12:19.147011 139665004287872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0219 11:12:19.500665 139665004287872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0219 11:12:21.893357 139665004287872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-19T11:12:21Z\n",
            "I0219 11:12:21.911748 139665004287872 evaluation.py:255] Starting evaluation at 2020-02-19T11:12:21Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0219 11:12:22.112501 139665004287872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from train_model.py/model.ckpt-4074\n",
            "I0219 11:12:22.114571 139665004287872 saver.py:1284] Restoring parameters from train_model.py/model.ckpt-4074\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0219 11:12:22.455914 139665004287872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0219 11:12:22.532148 139665004287872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "I0219 11:12:24.877454 139665004287872 evaluation.py:167] Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "I0219 11:12:25.985961 139665004287872 evaluation.py:167] Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "I0219 11:12:26.943660 139665004287872 evaluation.py:167] Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "I0219 11:12:27.918091 139665004287872 evaluation.py:167] Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "I0219 11:12:29.840723 139665004287872 evaluation.py:167] Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "I0219 11:12:30.986064 139665004287872 evaluation.py:167] Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "I0219 11:12:32.087278 139665004287872 evaluation.py:167] Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "I0219 11:12:33.146370 139665004287872 evaluation.py:167] Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "I0219 11:12:34.793546 139665004287872 evaluation.py:167] Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "I0219 11:12:36.007749 139665004287872 evaluation.py:167] Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-19-11:12:36\n",
            "I0219 11:12:36.132693 139665004287872 evaluation.py:275] Finished evaluation at 2020-02-19-11:12:36\n",
            "INFO:tensorflow:Saving dict for global step 4074: accuracy = 0.0725, global_step = 4074, loss = 4.7820005\n",
            "I0219 11:12:36.133026 139665004287872 estimator.py:2049] Saving dict for global step 4074: accuracy = 0.0725, global_step = 4074, loss = 4.7820005\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4074: train_model.py/model.ckpt-4074\n",
            "I0219 11:12:36.628362 139665004287872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4074: train_model.py/model.ckpt-4074\n",
            "INFO:tensorflow:global_step/sec: 1.2705\n",
            "I0219 11:13:30.700664 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.2705\n",
            "INFO:tensorflow:loss = 4.936083, step = 4163 (78.709 sec)\n",
            "I0219 11:13:30.702515 139665004287872 basic_session_run_hooks.py:260] loss = 4.936083, step = 4163 (78.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.53393\n",
            "I0219 11:14:35.892874 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.53393\n",
            "INFO:tensorflow:loss = 4.8651524, step = 4263 (65.192 sec)\n",
            "I0219 11:14:35.894960 139665004287872 basic_session_run_hooks.py:260] loss = 4.8651524, step = 4263 (65.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58751\n",
            "I0219 11:15:38.884733 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.58751\n",
            "INFO:tensorflow:loss = 3.8540816, step = 4363 (62.992 sec)\n",
            "I0219 11:15:38.887066 139665004287872 basic_session_run_hooks.py:260] loss = 3.8540816, step = 4363 (62.992 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.81679\n",
            "I0219 11:16:33.926896 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.81679\n",
            "INFO:tensorflow:loss = 4.7112923, step = 4463 (55.042 sec)\n",
            "I0219 11:16:33.929134 139665004287872 basic_session_run_hooks.py:260] loss = 4.7112923, step = 4463 (55.042 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4540 into train_model.py/model.ckpt.\n",
            "I0219 11:17:19.427868 139665004287872 basic_session_run_hooks.py:606] Saving checkpoints for 4540 into train_model.py/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0219 11:17:19.741874 139665004287872 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 1.7169\n",
            "I0219 11:17:32.171170 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.7169\n",
            "INFO:tensorflow:loss = 4.521148, step = 4563 (58.244 sec)\n",
            "I0219 11:17:32.173188 139665004287872 basic_session_run_hooks.py:260] loss = 4.521148, step = 4563 (58.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.52597\n",
            "I0219 11:18:37.703336 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.52597\n",
            "INFO:tensorflow:loss = 8.705061, step = 4663 (65.532 sec)\n",
            "I0219 11:18:37.705470 139665004287872 basic_session_run_hooks.py:260] loss = 8.705061, step = 4663 (65.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.63348\n",
            "I0219 11:19:38.922503 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.63348\n",
            "INFO:tensorflow:loss = 5.380801, step = 4763 (61.219 sec)\n",
            "I0219 11:19:38.924546 139665004287872 basic_session_run_hooks.py:260] loss = 5.380801, step = 4763 (61.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.64431\n",
            "I0219 11:20:39.737873 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.64431\n",
            "INFO:tensorflow:loss = 5.830614, step = 4863 (60.815 sec)\n",
            "I0219 11:20:39.739871 139665004287872 basic_session_run_hooks.py:260] loss = 5.830614, step = 4863 (60.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.91718\n",
            "I0219 11:21:31.898165 139665004287872 basic_session_run_hooks.py:692] global_step/sec: 1.91718\n",
            "INFO:tensorflow:loss = 4.30253, step = 4963 (52.161 sec)\n",
            "I0219 11:21:31.900541 139665004287872 basic_session_run_hooks.py:260] loss = 4.30253, step = 4963 (52.161 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into train_model.py/model.ckpt.\n",
            "I0219 11:21:52.984004 139665004287872 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into train_model.py/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0219 11:21:53.320564 139665004287872 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0219 11:21:53.407660 139665004287872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0219 11:21:55.981760 139665004287872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-19T11:21:56Z\n",
            "I0219 11:21:56.001106 139665004287872 evaluation.py:255] Starting evaluation at 2020-02-19T11:21:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0219 11:21:56.199226 139665004287872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from train_model.py/model.ckpt-5000\n",
            "I0219 11:21:56.201062 139665004287872 saver.py:1284] Restoring parameters from train_model.py/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0219 11:21:56.576914 139665004287872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0219 11:21:56.664484 139665004287872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "I0219 11:21:59.191599 139665004287872 evaluation.py:167] Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "I0219 11:22:00.289831 139665004287872 evaluation.py:167] Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "I0219 11:22:01.214747 139665004287872 evaluation.py:167] Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "I0219 11:22:02.138974 139665004287872 evaluation.py:167] Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "I0219 11:22:04.072261 139665004287872 evaluation.py:167] Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "I0219 11:22:05.259544 139665004287872 evaluation.py:167] Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "I0219 11:22:06.318441 139665004287872 evaluation.py:167] Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "I0219 11:22:07.315520 139665004287872 evaluation.py:167] Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "I0219 11:22:09.035196 139665004287872 evaluation.py:167] Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "I0219 11:22:10.297852 139665004287872 evaluation.py:167] Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-19-11:22:10\n",
            "I0219 11:22:10.428354 139665004287872 evaluation.py:275] Finished evaluation at 2020-02-19-11:22:10\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.08625, global_step = 5000, loss = 4.743012\n",
            "I0219 11:22:10.428741 139665004287872 estimator.py:2049] Saving dict for global step 5000: accuracy = 0.08625, global_step = 5000, loss = 4.743012\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: train_model.py/model.ckpt-5000\n",
            "I0219 11:22:10.429216 139665004287872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5000: train_model.py/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 4.090481.\n",
            "I0219 11:22:11.357784 139665004287872 estimator.py:371] Loss for final step: 4.090481.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8MZIjUEviwe",
        "colab_type": "text"
      },
      "source": [
        "trainmodel 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RdWXGqyvgkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Binary for training a RNN-based classifier for the Quick, Draw! data.\n",
        "python train_model.py \\\n",
        "  --training_data train_data \\\n",
        "  --eval_data eval_data \\\n",
        "  --model_dir /tmp/quickdraw_model/ \\\n",
        "  --cell_type cudnn_lstm\n",
        "When running on GPUs using --cell_type cudnn_lstm is much faster.\n",
        "The expected performance is ~75% in 1.5M steps with the default configuration.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import ast\n",
        "import functools\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_num_classes():\n",
        "  classes = []\n",
        "  with tf.gfile.GFile(FLAGS.classes_file, \"r\") as f:\n",
        "    classes = [x for x in f]\n",
        "  num_classes = len(classes)\n",
        "  return num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E75xi6vwwte",
        "colab_type": "text"
      },
      "source": [
        "get input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70s6uB3Swwcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_fn(mode, tfrecord_pattern, batch_size):\n",
        "  \"\"\"Creates an input_fn that stores all the data in memory.\n",
        "  Args:\n",
        "   mode: one of tf.contrib.learn.ModeKeys.{TRAIN, INFER, EVAL}\n",
        "   tfrecord_pattern: path to a TF record file created using create_dataset.py.\n",
        "   batch_size: the batch size to output.\n",
        "  Returns:\n",
        "    A valid input_fn for the model estimator.\n",
        "  \"\"\"\n",
        "\n",
        "  def _parse_tfexample_fn(example_proto, mode):\n",
        "    \"\"\"Parse a single record which is expected to be a tensorflow.Example.\"\"\"\n",
        "    feature_to_type = {\n",
        "        \"ink\": tf.VarLenFeature(dtype=tf.float32),\n",
        "        \"shape\": tf.FixedLenFeature([2], dtype=tf.int64)\n",
        "    }\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "      # The labels won't be available at inference time, so don't add them\n",
        "      # to the list of feature_columns to be read.\n",
        "      feature_to_type[\"class_index\"] = tf.FixedLenFeature([1], dtype=tf.int64)\n",
        "\n",
        "    parsed_features = tf.parse_single_example(example_proto, feature_to_type)\n",
        "    labels = None\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "      labels = parsed_features[\"class_index\"]\n",
        "    parsed_features[\"ink\"] = tf.sparse_tensor_to_dense(parsed_features[\"ink\"])\n",
        "    return parsed_features, labels\n",
        "\n",
        "  def _input_fn():\n",
        "    \"\"\"Estimator `input_fn`.\n",
        "    Returns:\n",
        "      A tuple of:\n",
        "      - Dictionary of string feature name to `Tensor`.\n",
        "      - `Tensor` of target labels.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset.list_files(tfrecord_pattern)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      dataset = dataset.shuffle(buffer_size=10)\n",
        "    dataset = dataset.repeat()\n",
        "    # Preprocesses 10 files concurrently and interleaves records from each file.\n",
        "    dataset = dataset.interleave(\n",
        "        tf.data.TFRecordDataset,\n",
        "        cycle_length=10,\n",
        "        block_length=1)\n",
        "    dataset = dataset.map(\n",
        "        functools.partial(_parse_tfexample_fn, mode=mode),\n",
        "        num_parallel_calls=10)\n",
        "    dataset = dataset.prefetch(10000)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      dataset = dataset.shuffle(buffer_size=1000000)\n",
        "    # Our inputs are variable length, so pad them.\n",
        "    dataset = dataset.padded_batch(\n",
        "        batch_size, padded_shapes=dataset.output_shapes)\n",
        "    features, labels = dataset.make_one_shot_iterator().get_next()\n",
        "    return features, labels\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUNz-DSNwTIv",
        "colab_type": "text"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uiVa3AswRtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "  \"\"\"Model function for RNN classifier.\n",
        "  This function sets up a neural network which applies convolutional layers (as\n",
        "  configured with params.num_conv and params.conv_len) to the input.\n",
        "  The output of the convolutional layers is given to LSTM layers (as configured\n",
        "  with params.num_layers and params.num_nodes).\n",
        "  The final state of the all LSTM layers are concatenated and fed to a fully\n",
        "  connected layer to obtain the final classification scores.\n",
        "  Args:\n",
        "    features: dictionary with keys: inks, lengths.\n",
        "    labels: one hot encoded classes\n",
        "    mode: one of tf.estimator.ModeKeys.{TRAIN, INFER, EVAL}\n",
        "    params: a parameter dictionary with the following keys: num_layers,\n",
        "      num_nodes, batch_size, num_conv, conv_len, num_classes, learning_rate.\n",
        "  Returns:\n",
        "    ModelFnOps for Estimator API.\n",
        "  \"\"\"\n",
        "\n",
        "  def _get_input_tensors(features, labels):\n",
        "    \"\"\"Converts the input dict into inks, lengths, and labels tensors.\"\"\"\n",
        "    # features[ink] is a sparse tensor that is [8, batch_maxlen, 3]\n",
        "    # inks will be a dense tensor of [8, maxlen, 3]\n",
        "    # shapes is [batchsize, 2]\n",
        "    shapes = features[\"shape\"]\n",
        "    # lengths will be [batch_size]\n",
        "    lengths = tf.squeeze(\n",
        "        tf.slice(shapes, begin=[0, 0], size=[params.batch_size, 1]))\n",
        "    inks = tf.reshape(features[\"ink\"], [params.batch_size, -1, 3])\n",
        "    if labels is not None:\n",
        "      labels = tf.squeeze(labels)\n",
        "    return inks, lengths, labels\n",
        "\n",
        "  def _add_conv_layers(inks, lengths):\n",
        "    \"\"\"Adds convolution layers.\"\"\"\n",
        "    convolved = inks\n",
        "    for i in range(len(params.num_conv)):\n",
        "      convolved_input = convolved\n",
        "      if params.batch_norm:\n",
        "        convolved_input = tf.layers.batch_normalization(\n",
        "            convolved_input,\n",
        "            training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "      # Add dropout layer if enabled and not first convolution layer.\n",
        "      if i > 0 and params.dropout:\n",
        "        convolved_input = tf.layers.dropout(\n",
        "            convolved_input,\n",
        "            rate=params.dropout,\n",
        "            training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "      convolved = tf.layers.conv1d(\n",
        "          convolved_input,\n",
        "          filters=params.num_conv[i],\n",
        "          kernel_size=params.conv_len[i],\n",
        "          activation=None,\n",
        "          strides=1,\n",
        "          padding=\"same\",\n",
        "          name=\"conv1d_%d\" % i)\n",
        "    return convolved, lengths\n",
        "\n",
        "  def _add_regular_rnn_layers(convolved, lengths):\n",
        "    \"\"\"Adds RNN layers.\"\"\"\n",
        "    if params.cell_type == \"lstm\":\n",
        "      cell = tf.nn.rnn_cell.BasicLSTMCell\n",
        "    elif params.cell_type == \"block_lstm\":\n",
        "      cell = tf.contrib.rnn.LSTMBlockCell\n",
        "    cells_fw = [cell(params.num_nodes) for _ in range(params.num_layers)]\n",
        "    cells_bw = [cell(params.num_nodes) for _ in range(params.num_layers)]\n",
        "    if params.dropout > 0.0:\n",
        "      cells_fw = [tf.contrib.rnn.DropoutWrapper(cell) for cell in cells_fw]\n",
        "      cells_bw = [tf.contrib.rnn.DropoutWrapper(cell) for cell in cells_bw]\n",
        "    outputs, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
        "        cells_fw=cells_fw,\n",
        "        cells_bw=cells_bw,\n",
        "        inputs=convolved,\n",
        "        sequence_length=lengths,\n",
        "        dtype=tf.float32,\n",
        "        scope=\"rnn_classification\")\n",
        "    return outputs\n",
        "\n",
        "  def _add_cudnn_rnn_layers(convolved):\n",
        "    \"\"\"Adds CUDNN LSTM layers.\"\"\"\n",
        "    # Convolutions output [B, L, Ch], while CudnnLSTM is time-major.\n",
        "    convolved = tf.transpose(convolved, [1, 0, 2])\n",
        "    lstm = tf.contrib.cudnn_rnn.CudnnLSTM(\n",
        "        num_layers=params.num_layers,\n",
        "        num_units=params.num_nodes,\n",
        "        dropout=params.dropout if mode == tf.estimator.ModeKeys.TRAIN else 0.0,\n",
        "        direction=\"bidirectional\")\n",
        "    outputs, _ = lstm(convolved)\n",
        "    # Convert back from time-major outputs to batch-major outputs.\n",
        "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
        "    return outputs\n",
        "\n",
        "  def _add_rnn_layers(convolved, lengths):\n",
        "    \"\"\"Adds recurrent neural network layers depending on the cell type.\"\"\"\n",
        "    if params.cell_type != \"cudnn_lstm\":\n",
        "      outputs = _add_regular_rnn_layers(convolved, lengths)\n",
        "    else:\n",
        "      outputs = _add_cudnn_rnn_layers(convolved)\n",
        "    # outputs is [batch_size, L, N] where L is the maximal sequence length and N\n",
        "    # the number of nodes in the last layer.\n",
        "    mask = tf.tile(\n",
        "        tf.expand_dims(tf.sequence_mask(lengths, tf.shape(outputs)[1]), 2),\n",
        "        [1, 1, tf.shape(outputs)[2]])\n",
        "    zero_outside = tf.where(mask, outputs, tf.zeros_like(outputs))\n",
        "    outputs = tf.reduce_sum(zero_outside, axis=1)\n",
        "    return outputs\n",
        "\n",
        "  def _add_fc_layers(final_state):\n",
        "    \"\"\"Adds a fully connected layer.\"\"\"\n",
        "    return tf.layers.dense(final_state, params.num_classes)\n",
        "\n",
        "  # Build the model.\n",
        "  inks, lengths, labels = _get_input_tensors(features, labels)\n",
        "  convolved, lengths = _add_conv_layers(inks, lengths)\n",
        "  final_state = _add_rnn_layers(convolved, lengths)\n",
        "  logits = _add_fc_layers(final_state)\n",
        "  # Add the loss.\n",
        "  cross_entropy = tf.reduce_mean(\n",
        "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          labels=labels, logits=logits))\n",
        "  # Add the optimizer.\n",
        "  train_op = tf.contrib.layers.optimize_loss(\n",
        "      loss=cross_entropy,\n",
        "      global_step=tf.train.get_global_step(),\n",
        "      learning_rate=params.learning_rate,\n",
        "      optimizer=\"Adam\",\n",
        "      # some gradient clipping stabilizes training in the beginning.\n",
        "      clip_gradients=params.gradient_clipping_norm,\n",
        "      summaries=[\"learning_rate\", \"loss\", \"gradients\", \"gradient_norm\"])\n",
        "  # Compute current predictions.\n",
        "  predictions = tf.argmax(logits, axis=1)\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions={\"logits\": logits, \"predictions\": predictions},\n",
        "      loss=cross_entropy,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops={\"accuracy\": tf.metrics.accuracy(labels, predictions)})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaLJxHgnwT-1",
        "colab_type": "text"
      },
      "source": [
        "CREATE_ESTIMATOR_AND_SPECS\n",
        "\n",
        "-> tf.contrib.training.HParams => 2.0에서 삭제!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bqTkgsrwUvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_estimator_and_specs(run_config):\n",
        "  \"\"\"Creates an Experiment configuration based on the estimator and input fn.\"\"\"\n",
        "  model_params = tf.contrib.training.HParams(\n",
        "      num_layers=FLAGS.num_layers,\n",
        "      num_nodes=FLAGS.num_nodes,\n",
        "      batch_size=FLAGS.batch_size,\n",
        "      num_conv=ast.literal_eval(FLAGS.num_conv),\n",
        "      conv_len=ast.literal_eval(FLAGS.conv_len),\n",
        "      num_classes=get_num_classes(),\n",
        "      learning_rate=FLAGS.learning_rate,\n",
        "      gradient_clipping_norm=FLAGS.gradient_clipping_norm,\n",
        "      cell_type=FLAGS.cell_type,\n",
        "      batch_norm=FLAGS.batch_norm,\n",
        "      dropout=FLAGS.dropout)\n",
        "\n",
        "  estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params=model_params)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(input_fn=get_input_fn(\n",
        "      mode=tf.estimator.ModeKeys.TRAIN,\n",
        "      tfrecord_pattern=FLAGS.training_data,\n",
        "      batch_size=FLAGS.batch_size), max_steps=FLAGS.steps)\n",
        "\n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn=get_input_fn(\n",
        "      mode=tf.estimator.ModeKeys.EVAL,\n",
        "      tfrecord_pattern=FLAGS.eval_data,\n",
        "      batch_size=FLAGS.batch_size))\n",
        "\n",
        "  return estimator, train_spec, eval_spec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS84yQJuwcFH",
        "colab_type": "text"
      },
      "source": [
        "MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naiNuOy5wcPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(unused_args):\n",
        "  estimator, train_spec, eval_spec = create_estimator_and_specs(\n",
        "      run_config=tf.estimator.RunConfig(\n",
        "          model_dir=FLAGS.model_dir,\n",
        "          save_checkpoints_secs=300,\n",
        "          save_summary_steps=100))\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
        "  parser.add_argument(\n",
        "      \"--training_data\",\n",
        "      type=str,\n",
        "      default=\"\",\n",
        "      help=\"Path to training data (tf.Example in TFRecord format)\")\n",
        "  parser.add_argument(\n",
        "      \"--eval_data\",\n",
        "      type=str,\n",
        "      default=\"\",\n",
        "      help=\"Path to evaluation data (tf.Example in TFRecord format)\")\n",
        "  parser.add_argument(\n",
        "      \"--classes_file\",\n",
        "      type=str,\n",
        "      default=\"\",\n",
        "      help=\"Path to a file with the classes - one class per line\")\n",
        "  parser.add_argument(\n",
        "      \"--num_layers\",\n",
        "      type=int,\n",
        "      default=3,\n",
        "      help=\"Number of recurrent neural network layers.\")\n",
        "  parser.add_argument(\n",
        "      \"--num_nodes\",\n",
        "      type=int,\n",
        "      default=128,\n",
        "      help=\"Number of node per recurrent network layer.\")\n",
        "  parser.add_argument(\n",
        "      \"--num_conv\",\n",
        "      type=str,\n",
        "      default=\"[48, 64, 96]\",\n",
        "      help=\"Number of conv layers along with number of filters per layer.\")\n",
        "  parser.add_argument(\n",
        "      \"--conv_len\",\n",
        "      type=str,\n",
        "      default=\"[5, 5, 3]\",\n",
        "      help=\"Length of the convolution filters.\")\n",
        "  parser.add_argument(\n",
        "      \"--cell_type\",\n",
        "      type=str,\n",
        "      default=\"lstm\",\n",
        "      help=\"Cell type used for rnn layers: cudnn_lstm, lstm or block_lstm.\")\n",
        "  parser.add_argument(\n",
        "      \"--batch_norm\",\n",
        "      type=\"bool\",\n",
        "      default=\"False\",\n",
        "      help=\"Whether to enable batch normalization or not.\")\n",
        "  parser.add_argument(\n",
        "      \"--learning_rate\",\n",
        "      type=float,\n",
        "      default=0.0001,\n",
        "      help=\"Learning rate used for training.\")\n",
        "  parser.add_argument(\n",
        "      \"--gradient_clipping_norm\",\n",
        "      type=float,\n",
        "      default=9.0,\n",
        "      help=\"Gradient clipping norm used during training.\")\n",
        "  parser.add_argument(\n",
        "      \"--dropout\",\n",
        "      type=float,\n",
        "      default=0.3,\n",
        "      help=\"Dropout used for convolutions and bidi lstm layers.\")\n",
        "  parser.add_argument(\n",
        "      \"--steps\",\n",
        "      type=int,\n",
        "      default=100000,\n",
        "      help=\"Number of training steps.\")\n",
        "  parser.add_argument(\n",
        "      \"--batch_size\",\n",
        "      type=int,\n",
        "      default=8,\n",
        "      help=\"Batch size to use for training/evaluation.\")\n",
        "  parser.add_argument(\n",
        "      \"--model_dir\",\n",
        "      type=str,\n",
        "      default=\"\",\n",
        "      help=\"Path for storing the model checkpoints.\")\n",
        "  parser.add_argument(\n",
        "      \"--self_test\",\n",
        "      type=\"bool\",\n",
        "      default=\"False\",\n",
        "      help=\"Whether to enable batch normalization or not.\")\n",
        "\n",
        "  FLAGS, unparsed = parser.parse_known_args()\n",
        "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_X0apNYBBFP",
        "colab_type": "text"
      },
      "source": [
        "아래 명령어는 tensorflow 1.x버전의 소스코드를 자동으로 tensorflow 2.0버전의 소스코드로 변환해주는 명령어 이다.\n",
        "\n",
        "대부분 동작을 하지만 tensorflow 2.0에서는 tf.contrib 모듈가 삭제되었으며\n",
        "\n",
        " tf.compat.v1 모듈에도 수록되지 않았으므로 이는 개인이 알아서 해결해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGqpQcBv8eDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "235fefc3-e085-4fbd-d12a-4682d15e8592"
      },
      "source": [
        "!tf_upgrade_v2 --infile ./drive/My\\ Drive/train_model.py --outfile ./drive/My\\ Drive/train_model-upgraded.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO line 41:7: Renamed 'tf.gfile.GFile' to 'tf.io.gfile.GFile'\n",
            "INFO line 60:15: Renamed 'tf.VarLenFeature' to 'tf.io.VarLenFeature'\n",
            "INFO line 61:17: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 66:39: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 68:22: Added keywords to args of function 'tf.parse_single_example'\n",
            "INFO line 68:22: Renamed 'tf.parse_single_example' to 'tf.io.parse_single_example'\n",
            "INFO line 72:29: Renamed 'tf.sparse_tensor_to_dense' to 'tf.sparse.to_dense'\n",
            "WARNING line 100:23: Changing dataset.make_one_shot_iterator() to tf.compat.v1.data.make_one_shot_iterator(dataset). Please check this transformation.\n",
            "\n",
            "INFO line 144:26: Renamed 'tf.layers.batch_normalization' to 'tf.compat.v1.layers.batch_normalization'\n",
            "INFO line 149:26: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 153:18: Renamed 'tf.layers.conv1d' to 'tf.compat.v1.layers.conv1d'\n",
            "INFO line 166:13: Renamed 'tf.nn.rnn_cell.BasicLSTMCell' to 'tf.compat.v1.nn.rnn_cell.BasicLSTMCell'\n",
            "WARNING line 168:13: Using member tf.contrib.rnn.LSTMBlockCell in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "ERROR line 168:13: Using member tf.contrib.rnn.LSTMBlockCell in deprecated module tf.contrib. tf.contrib.rnn.LSTMBlockCell cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "WARNING line 172:18: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "ERROR line 172:18: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib. tf.contrib.rnn.DropoutWrapper cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "WARNING line 173:18: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "ERROR line 173:18: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib. tf.contrib.rnn.DropoutWrapper cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "WARNING line 174:20: Using member tf.contrib.rnn.stack_bidirectional_dynamic_rnn in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "ERROR line 174:20: Using member tf.contrib.rnn.stack_bidirectional_dynamic_rnn in deprecated module tf.contrib. tf.contrib.rnn.stack_bidirectional_dynamic_rnn cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "INFO line 186:16: Added keywords to args of function 'tf.transpose'\n",
            "WARNING line 187:11: Using member tf.contrib.cudnn_rnn.CudnnLSTM in deprecated module tf.contrib.cudnn_rnn. (Manual edit required) tf.contrib.cudnn_rnn.* has been deprecated, and the CuDNN kernel has been integrated with tf.keras.layers.LSTM/GRU in TensorFlow 2.0. Please check the new API and use that instead.\n",
            "ERROR line 187:11: Using member tf.contrib.cudnn_rnn.CudnnLSTM in deprecated module tf.contrib. tf.contrib.cudnn_rnn.CudnnLSTM cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "INFO line 194:14: Added keywords to args of function 'tf.transpose'\n",
            "INFO line 206:49: Added keywords to args of function 'tf.shape'\n",
            "INFO line 207:15: Added keywords to args of function 'tf.shape'\n",
            "INFO line 208:19: Renamed 'tf.where' to 'tf.compat.v1.where'\n",
            "INFO line 209:14: Added keywords to args of function 'tf.reduce_sum'\n",
            "INFO line 214:11: Renamed 'tf.layers.dense' to 'tf.compat.v1.layers.dense'\n",
            "INFO line 222:18: Added keywords to args of function 'tf.reduce_mean'\n",
            "ERROR line 226:13: Using member tf.contrib.layers.optimize_loss in deprecated module tf.contrib. tf.contrib.layers.optimize_loss cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "INFO line 228:18: Renamed 'tf.train.get_global_step' to 'tf.compat.v1.train.get_global_step'\n",
            "INFO line 235:16: Added keywords to args of function 'tf.argmax'\n",
            "INFO line 241:35: tf.metrics.accuracy requires manual check. tf.metrics have been replaced with object oriented versions in TF 2.0 and after. The metric function calls have been converted to compat.v1 for backward compatibility. Please update these calls to the TF 2.0 versions.\n",
            "INFO line 241:35: Renamed 'tf.metrics.accuracy' to 'tf.compat.v1.metrics.accuracy'\n",
            "ERROR line 246:17: Using member tf.contrib.training.HParams in deprecated module tf.contrib. tf.contrib.training.HParams cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 13 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: ./drive/My Drive/train_model.py\n",
            "--------------------------------------------------------------------------------\n",
            "./drive/My Drive/train_model.py:100:23: WARNING: Changing dataset.make_one_shot_iterator() to tf.compat.v1.data.make_one_shot_iterator(dataset). Please check this transformation.\n",
            "\n",
            "./drive/My Drive/train_model.py:168:13: WARNING: Using member tf.contrib.rnn.LSTMBlockCell in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "./drive/My Drive/train_model.py:168:13: ERROR: Using member tf.contrib.rnn.LSTMBlockCell in deprecated module tf.contrib. tf.contrib.rnn.LSTMBlockCell cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "./drive/My Drive/train_model.py:172:18: WARNING: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "./drive/My Drive/train_model.py:172:18: ERROR: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib. tf.contrib.rnn.DropoutWrapper cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "./drive/My Drive/train_model.py:173:18: WARNING: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "./drive/My Drive/train_model.py:173:18: ERROR: Using member tf.contrib.rnn.DropoutWrapper in deprecated module tf.contrib. tf.contrib.rnn.DropoutWrapper cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "./drive/My Drive/train_model.py:174:20: WARNING: Using member tf.contrib.rnn.stack_bidirectional_dynamic_rnn in deprecated module tf.contrib.rnn. (Manual edit required) tf.contrib.rnn.* has been deprecated, and widely used cells/functions will be moved to tensorflow/addons repository. Please check it there and file Github issues if necessary.\n",
            "./drive/My Drive/train_model.py:174:20: ERROR: Using member tf.contrib.rnn.stack_bidirectional_dynamic_rnn in deprecated module tf.contrib. tf.contrib.rnn.stack_bidirectional_dynamic_rnn cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "./drive/My Drive/train_model.py:187:11: WARNING: Using member tf.contrib.cudnn_rnn.CudnnLSTM in deprecated module tf.contrib.cudnn_rnn. (Manual edit required) tf.contrib.cudnn_rnn.* has been deprecated, and the CuDNN kernel has been integrated with tf.keras.layers.LSTM/GRU in TensorFlow 2.0. Please check the new API and use that instead.\n",
            "./drive/My Drive/train_model.py:187:11: ERROR: Using member tf.contrib.cudnn_rnn.CudnnLSTM in deprecated module tf.contrib. tf.contrib.cudnn_rnn.CudnnLSTM cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "./drive/My Drive/train_model.py:226:13: ERROR: Using member tf.contrib.layers.optimize_loss in deprecated module tf.contrib. tf.contrib.layers.optimize_loss cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "./drive/My Drive/train_model.py:246:17: ERROR: Using member tf.contrib.training.HParams in deprecated module tf.contrib. tf.contrib.training.HParams cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report.txt'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}