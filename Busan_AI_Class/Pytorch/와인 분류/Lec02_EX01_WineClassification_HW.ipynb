{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Lec02_EX01_WineClassification_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLxKj4aRljRY"
      },
      "source": [
        "# Step1. 관련 패키지 및 모듈 import 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d43Pf4GLH6n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabb6df3-07ac-4763-be4e-546121beb448"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npj-HOaSljRa"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.nn import init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51FcFUpvljRd"
      },
      "source": [
        "# Step 2. 와인 데이터셋 구성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFM4iCUNWGYw"
      },
      "source": [
        "https://archive.ics.uci.edu/ml/datasets/wine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_aybu-KljRe"
      },
      "source": [
        "colnames=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', 'class'] \n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CNN-main/CNNPytorchCodes/data/wine.csv',names=colnames)\n",
        "train_data = train_data.sample(frac = 1, random_state = 123)\n",
        "test_data = train_data.iloc[5000:,:]\n",
        "test_label = test_data['class']\n",
        "test_data = test_data.drop(labels='class',axis=1)\n",
        "# train_label = train_data.iloc[:5000,-1]\n",
        "train_data = train_data.iloc[:5000,:]\n",
        "# Generate Test Label\n",
        "# test_label = pd.DataFrame([0. if item == '0' else 1. for item in test_data['class']])\n",
        "# test_label = [0. if item == 0 else 1. for item in test_data['class']]\n",
        "\n",
        "# drop the class infromation\n",
        "# test_data = test_data.drop(['class'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNlIT6nWFBcY",
        "outputId": "7d9c9ed1-99d7-4fff-820b-4e257e1eeef2"
      },
      "source": [
        "test_label.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY3n4Ea8ljRg"
      },
      "source": [
        "# Step 3. 다층퍼셉트론 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1LGYuMPljRh"
      },
      "source": [
        "class mymodel(nn.Module):\n",
        "    def __init__(self, is_train=True):        \n",
        "        super(mymodel, self).__init__()\n",
        "        ################################\n",
        "        ## Problem #1\n",
        "        self.l1 = torch.nn.Linear(12, 8)\n",
        "        self.l2 = torch.nn.Linear(8, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 2)\n",
        "        ################################\n",
        "                        \n",
        "    def forward(self, x):        \n",
        "        ################################\n",
        "        ## Problem #1   \n",
        "        x = torch.sigmoid(self.l1(x))\n",
        "        x = torch.sigmoid(self.l2(x))\n",
        "        x = torch.sigmoid(self.l3(x))\n",
        "        ################################        \n",
        "        return x\n",
        "\n",
        "model = mymodel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dngQ3v_0ljRj"
      },
      "source": [
        "# 모델 구조 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thZlJmXQljRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82df353e-3e80-4d9c-f1f5-f11fb1371b44"
      },
      "source": [
        "def print_network(model):    \n",
        "    def _get_network_description(network):\n",
        "        '''Get the string and total parameters of the network'''\n",
        "        if isinstance(network, nn.DataParallel):\n",
        "            network = network.module\n",
        "        s = str(network)\n",
        "        n = sum(map(lambda x: x.numel(), network.parameters()))\n",
        "        return s, n\n",
        "    s, n = _get_network_description(model)\n",
        "    if isinstance(model, nn.DataParallel):\n",
        "        net_struc_str = '{} - {}'.format(model.__class__.__name__, model.module.__class__.__name__)\n",
        "    else: net_struc_str = '{}'.format(model.__class__.__name__)\n",
        "    log = 'Network structure: {}, with parameters: {:,d}'.format(net_struc_str, n)\n",
        "    return log, s\n",
        "\n",
        "\n",
        "log, architecture = print_network(model)\n",
        "print(log)\n",
        "print(architecture)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network structure: mymodel, with parameters: 150\n",
            "mymodel(\n",
            "  (l1): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (l2): Linear(in_features=8, out_features=4, bias=True)\n",
            "  (l3): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD_AGb01ljRn"
      },
      "source": [
        "# Step 4. Training 함수 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4ip4lQ_ljRn"
      },
      "source": [
        "def train(train_data, test_data, test_label, batch_size=1000, epochs=1000, learning_rate = 5e-4):\n",
        "    # training on cpu\n",
        "    device = torch.device('cpu')\n",
        "    # random seed\n",
        "    torch.manual_seed(1)\n",
        "    # define model\n",
        "    model = mymodel().to(device)\n",
        "    # optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))        \n",
        "    # loss fucntion\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    \n",
        "    # now start Training!!!\n",
        "    running_loss = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        # shuffling every epoch        \n",
        "        train_data_shuffle = train_data\n",
        "        train_label_shuffle = pd.DataFrame([0. if item == '0' else 1. for item in train_data_shuffle['class']])\n",
        "        train_label_shuffle = [0. if item == 0 else 1. for item in train_data_shuffle['class']]\n",
        "\n",
        "        train_data_shuffle = train_data_shuffle.drop(['class'], axis=1)\n",
        "\n",
        "\n",
        "        for start, end in zip(range(0, len(train_data_shuffle), batch_size), range(batch_size, len(train_data_shuffle), batch_size)):       \n",
        "\n",
        "            inputs = torch.from_numpy(train_data_shuffle[start:end].values).to(device)\n",
        "            inputs = inputs.float()\n",
        "            labels = torch.Tensor(train_label_shuffle[start:end]).to(device)\n",
        "            labels = labels.long()\n",
        "                 \n",
        "            outputs = model(inputs) # 데이터를 모델에 통과하여 결과 예측(순전파)\n",
        "            optimizer.zero_grad()            \n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            ######################################################\n",
        "            ### Problem 2: Backpropagation, Updating Model Weight\n",
        "            ######################################################\n",
        "            loss.backward() # 해당 결과를 기반으로 오류 검사\n",
        "            optimizer.step() # 손실을 바탕으로 역전파 진행 \n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "        \n",
        "              \n",
        "        total = 0\n",
        "        correct = 0\n",
        "        if epoch % 50 == 0 or epoch +1 == epochs:\n",
        "            model.eval()\n",
        "            with torch.no_grad(): \n",
        "                total = len(test_label)\n",
        "                test_outputs = model(Variable(torch.from_numpy(test_data.values).float()).to(device))               \n",
        "                ###################################################\n",
        "                #### Problem 3: Test model every 50 epochs\n",
        "                ###################################################\n",
        "                _, predicted = torch.max(test_outputs.data, 1)\n",
        "                predicted = predicted.numpy()\n",
        "                correct += (predicted == test_label).sum().item()                             \n",
        "                print('[Epoch: {}] [Training Loss: {:.6f}] [Accuracy: {:.6f}]'.format(epoch, running_loss / batch_size, correct/total))\n",
        "                running_loss = 0.0\n",
        "        model.train()\n",
        "    print(\"End Training!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teM7SAf5ljRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1d2c70-9d96-4f30-f05f-9f162ee4b454"
      },
      "source": [
        "train(train_data, test_data, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 0] [Training Loss: 0.002893] [Accuracy: 0.235805]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 50] [Training Loss: 0.138586] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 100] [Training Loss: 0.129789] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 150] [Training Loss: 0.123216] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 200] [Training Loss: 0.118035] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 250] [Training Loss: 0.113593] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 300] [Training Loss: 0.109538] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 350] [Training Loss: 0.105724] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 400] [Training Loss: 0.102002] [Accuracy: 0.764195]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 450] [Training Loss: 0.098470] [Accuracy: 0.922512]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 500] [Training Loss: 0.095199] [Accuracy: 0.941216]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 550] [Training Loss: 0.092236] [Accuracy: 0.943888]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 600] [Training Loss: 0.089612] [Accuracy: 0.947896]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 650] [Training Loss: 0.087298] [Accuracy: 0.949232]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 700] [Training Loss: 0.085244] [Accuracy: 0.949900]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 750] [Training Loss: 0.083422] [Accuracy: 0.953240]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 800] [Training Loss: 0.081720] [Accuracy: 0.952572]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 850] [Training Loss: 0.079802] [Accuracy: 0.959252]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 900] [Training Loss: 0.077860] [Accuracy: 0.962592]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 950] [Training Loss: 0.076435] [Accuracy: 0.963260]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "[Epoch: 999] [Training Loss: 0.073776] [Accuracy: 0.963928]\n",
            "End Training!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}